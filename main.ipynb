{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dff634f-8241-4a38-ad49-a3daa42aa70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Marina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Marina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mrjob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marina\\OneDrive\\Documents\\GitHub\\3HW-ADM-Fabri.Dinino.Aur\\main.ipynb Cella 1\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marina/OneDrive/Documents/GitHub/3HW-ADM-Fabri.Dinino.Aur/main.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marina/OneDrive/Documents/GitHub/3HW-ADM-Fabri.Dinino.Aur/main.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m TfidfVectorizer    \u001b[39m#Useful already implemented tfidf vectorizer from scikit learn library\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Marina/OneDrive/Documents/GitHub/3HW-ADM-Fabri.Dinino.Aur/main.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmrjob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjob\u001b[39;00m \u001b[39mimport\u001b[39;00m MRJob\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marina/OneDrive/Documents/GitHub/3HW-ADM-Fabri.Dinino.Aur/main.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmrjob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstep\u001b[39;00m \u001b[39mimport\u001b[39;00m MRStep                                  \u001b[39m#MapReduce methods to perform the map-shuffle-reduce pattern\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marina/OneDrive/Documents/GitHub/3HW-ADM-Fabri.Dinino.Aur/main.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mheapq\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mrjob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import lxml\n",
    "import numpy as np\n",
    "\n",
    "import os                                                      #Needed to move between OS folders\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup                                  #Scraper \n",
    "import requests                                                #URL drainer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime                                  #To be leveraged to define datetime objects  \n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "import nltk                                                    #Text processing library\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')                                         #Download command on NLTK library to get specific \n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer    #Useful already implemented tfidf vectorizer from scikit learn library\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep                                  #MapReduce methods to perform the map-shuffle-reduce pattern\n",
    "\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe6532-7b2b-43fc-bbf1-b282d87c4cb4",
   "metadata": {},
   "source": [
    "# 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c53cba-0b9d-4db4-a286-aaeb7c0bb170",
   "metadata": {},
   "source": [
    "## 1.1. Get the list of places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfa368-8991-4b48-8ef8-21f99eff73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "\n",
    "for i in range(1,401):\n",
    "    main_url = 'https://www.atlasobscura.com/places?page=' + str(i) +'&sort=likes_count'\n",
    "    cont = requests.get(main_url)\n",
    "    soup = BeautifulSoup(cont.text)\n",
    "    for place in soup.find_all('a', {'class':'content-card content-card-place'}):\n",
    "        places.append('https://www.atlasobscura.com'+place.get('href'))\n",
    "\n",
    "f = open('places.txt','w+')\n",
    "\n",
    "for place in places:\n",
    "    f.write(place+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d4b30-cacf-4157-bba6-f135886f9b71",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb929137-405c-4738-a256-d8e887c6d351",
   "metadata": {},
   "source": [
    "## 1.2 Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034aa15-b321-47e6-9200-7c5f87340f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('places.txt','r')\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "dic = {}\n",
    "for i in range(0,7200,18):\n",
    "    dic[1+i//18] = lines[i:i+18]\n",
    "\n",
    "for page in range(0,401):\n",
    "    try:\n",
    "        os.mkdir(r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\page ' + str(page))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    path = r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\page ' + str(page)\n",
    "    os.chdir(path)\n",
    "\n",
    "    for place in dic[page]:\n",
    "        place_name = place[36:len(place)-1]\n",
    "        vanilla = requests.get(place[:-1],allow_redirects=False,headers = {'User-agent': 'your bot 0.1'})\n",
    "        \n",
    "        with open(place_name+\".txt\",'w+',encoding=\"utf-8\") as new_file:\n",
    "            new_file.write(vanilla.text)\n",
    "\n",
    "os.chdir(r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430dcbd-e617-4b4b-9c90-0796e0cbad59",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0459e40-1e7d-4a14-987b-855837102c60",
   "metadata": {},
   "source": [
    "## 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a141e-07c6-4ef8-b2d8-7508fb9f5a81",
   "metadata": {},
   "source": [
    "We need to define a script to extract useful information from each HTML we collected. In particular we want these information:\n",
    "1. Place Name (to save as $placeName$): String.\n",
    "2. Place Tags (to save as $placeTags$): List of Strings.\n",
    "3. Number of people who have been there (to save as $numPeopleVisited$): Integer.\n",
    "4. Number of people who want to visit the place(to save as $numPeopleWant$): Integer.\n",
    "5. Description (to save as $placeDesc$): String. Everything from under the first image up to \"know before you go\" (orange frame on the example image).\n",
    "6. Short Description (to save as $placeShortDesc$): String. Everything from the title and location up to the image (blue frame on the example image).\n",
    "7. Nearby Places (to save as $placeNearby$): Extract the names of all nearby places, but only keep unique values: List of Strings.\n",
    "8. Address of the place(to save as $placeAddress$): String.\n",
    "9. Altitude and Longitude of the place's location(to save as $placeAlt$ and $placeLong$): Integers\n",
    "10. The username of the post editors (to save as $placeEditors$): List of Strings.\n",
    "11. Post publishing date (to save as $placePubDate$): datetime.\n",
    "12. The names of the lists that the place was included in (to save as $placeRelatedLists$): List of Strings.\n",
    "13. The names of the related places (to save as $placeRelatedPlaces$): List of Strings.\n",
    "14. The URL of the page of the place (to save as $placeURL$):String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab2494-ef9a-4781-937f-225005b6928e",
   "metadata": {},
   "source": [
    "We leverage *BeautifulSoup library* to scrape the information, but we need just an additional method to convert into a datetime object the post publishing date since it was a string in the format 'Month Day, Year'. For example we found 'May 8, 2010' for the very first link, and instead we wanted '2010/05/08'. This method does so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ae59c-ecbf-4ad3-bc06-5f5f97e8550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(string):\n",
    "    return str(datetime.strptime(string, '%B %d, %Y').date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba77953-7815-46b1-a045-eb77941ce15d",
   "metadata": {},
   "source": [
    "We define a function that builds a dictionary of information for every place we go through: then from this dictionary we'll buil a .tsv for every HTML document we gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c331df-bd9f-4ac9-ba0a-ba7f16196880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darkAtlasScraper(text):\n",
    "    \n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    scraped = {'placeName': 'NaN',\n",
    "               'placeTags': 'NaN',\n",
    "               'numPeopleVisited': 'NaN',\n",
    "               'numPeopleWant': 'NaN',\n",
    "               'placeDesc': 'NaN',\n",
    "               'placeShortDesc':'Nan',\n",
    "               'placeNearby': 'NaN',\n",
    "               'placeAddress': 'NaN',\n",
    "               'placeAlt': 'NaN',\n",
    "               'placeLong': 'NaN',\n",
    "               'placeEditors': 'NaN',\n",
    "               'placePubDate': 'NaN',\n",
    "               'placeRelatedPlaces': 'NaN',\n",
    "               'placeRelatedLists': 'NaN',\n",
    "               'placeURL': 'NaN'}          \n",
    "    \n",
    "    try:\n",
    "        scraped['placeName'] = soup.find_all('h1',{'class':'DDPage__header-title'})[0].contents[0]\n",
    "    except IndexError:\n",
    "        pass\n",
    "           \n",
    "    try:\n",
    "        scraped['placeTags'] = list(map(lambda s:s.strip(),\n",
    "                                        [tag.contents[0] for tag in soup.find_all('a',{'class':'itemTags__link js-item-tags-link'})]))\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    counters = soup.find_all('div',{'class':'title-md item-action-count'})\n",
    "    try:\n",
    "        scraped['numPeopleVisited'] = int(counters[0].contents[0])\n",
    "    except IndexError:\n",
    "        pass\n",
    "    try:\n",
    "        scraped['numPeopleWant'] = int(counters[1].contents[0])\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    place_desc = ''\n",
    "    for paragraph in soup.find_all('div',{'class':'DDP__body-copy'})[0].find_all('p'):\n",
    "        for element in paragraph.contents:\n",
    "            if re.search('<[^>]*>', str(element)):\n",
    "                element = re.sub('<[^>]*>', \"\", str(element))\n",
    "                place_desc += element\n",
    "            else:\n",
    "                place_desc += str(element)\n",
    "    scraped['placeDesc'] = place_desc\n",
    "    \n",
    "    try:\n",
    "        scraped['placeShortDesc'] = soup.find_all('h3',{'class':'DDPage__header-dek'})[0].contents[0].replace(u'\\xa0', u'')\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    nearby = []\n",
    "    try:\n",
    "        for nearbies in soup.find_all('div',{'class':'DDPageSiderailRecirc__item-text'}):\n",
    "            nearby.append(nearbies.find_all('div',{'class':'DDPageSiderailRecirc__item-title'})[0].contents[0])\n",
    "        scraped['placeNearby'] = nearby\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        address = (str(soup.find_all('aside',{'class':'DDPageSiderail__details'})[0]\n",
    "                           .find_all('address',{'class':'DDPageSiderail__address'})[0]\n",
    "                           .find_all('div')[0])\n",
    "                           .split('\\n', 1)[0])\n",
    "        scraped['placeAddress'] = re.sub('<[^>]*>', \" \", address)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    coordinates = soup.find_all('div',{'class':'DDPageSiderail__coordinates js-copy-coordinates'})[0].contents[2]\n",
    "    scraped['placeAlt'] = float(coordinates.split()[0][:-1])\n",
    "    scraped['placeLong'] = float(coordinates.split()[1])\n",
    "\n",
    "\n",
    "    editorsoup = soup.find_all('a',{'class':'DDPContributorsList__contributor'})\n",
    "    scraped['placeEditors'] = [stuff.find_all('span')[0].contents[0] \n",
    "                               for stuff in editorsoup \n",
    "                               if len(stuff.find_all('span')) > 0]\n",
    "    if not scraped['placeEditors']:\n",
    "        zzz = soup.find_all('div',{'class':'ugc-editors'})\n",
    "        flag = 0\n",
    "        for soupper in zzz:\n",
    "            if soupper.find_all('h6')[0].contents[0] == 'Added by':\n",
    "                flag = 1\n",
    "                break\n",
    "        try:\n",
    "            editorsoup = soup.find_all('div',{'class':'ugc-editors'})[flag].find_all('a',{'class':'DDPContributorsList__contributor'})\n",
    "            scraped['placeEditors'] = [editors.contents[0]\n",
    "                                       for editors in editorsoup]\n",
    "        except IndexError:\n",
    "            pass\n",
    "            \n",
    "    try:\n",
    "        scraped['placePubDate'] = string_to_datetime(soup.find_all('div',{'class':'DDPContributor__name'})[0].contents[0])\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    kircher = soup.find_all('div',{'class':'athanasius'})\n",
    "    for piece in kircher:\n",
    "        for piecer in piece.find_all('div',{'class':'CardRecircSection__title'}):\n",
    "            if piecer.contents[0] == 'Related Places':\n",
    "                scraped['placeRelatedPlaces'] = [re.sub('<[^>]*>', \"\", str(chunk.contents[1])) \n",
    "                                                 for chunk in piece.find_all('h3',{'class':'Card__heading --content-card-v2-title js-title-content'})]\n",
    "            elif 'Appears in' in piecer.contents[0]:\n",
    "                scraped['placeRelatedLists'] =  [re.sub('<[^>]*>', \"\", str(chunk.contents[1])) \n",
    "                                                 for chunk in piece.find_all('h3',{'class':'Card__heading --content-card-v2-title js-title-content'})]\n",
    "    \n",
    "    scraped['placeURL'] = 'https://www.atlasobscura.com/places/' + filename[:-4]\n",
    "    \n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb53fea-41ad-4584-84ea-8580afffcb0b",
   "metadata": {},
   "source": [
    "Now we have to define the script that goes through each folder and for each folder goes through each downloaded HTML, scrapes information and store them in a new .tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2407d-1215-48a3-83a5-313be2db3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1,401):\n",
    "    path = r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\page ' + str(page)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        os.chdir(r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\page ' + str(page))\n",
    "        \n",
    "        new_path = r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\page ' + str(page) + '\\\\' + filename\n",
    "        soupper = open(new_path, 'r',encoding=\"utf-8\")\n",
    "        \n",
    "        os.chdir(r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\tsv')\n",
    "        newer_path = r'C:\\\\Users\\\\Leonardo\\\\ADM_HW3\\\\tsv\\\\'+filename[:-4]+'.tsv'\n",
    "        try:\n",
    "            infos = darkAtlasScraper(soupper)\n",
    "        except IndexError:\n",
    "            print(newer_path)\n",
    "        with open(newer_path,'w+',encoding=\"utf-8\") as new_file:\n",
    "            for info in infos.values():\n",
    "                if type(info) == list:\n",
    "                    for index in range(len(info)):\n",
    "                        if index < len(info) - 1:\n",
    "                            new_file.write(str(info[index])+ ', ')\n",
    "                        elif index == len(info) - 1:\n",
    "                            new_file.write(str(info[index]))\n",
    "                    new_file.write('\\t')\n",
    "                else:\n",
    "                    new_file.write(str(info))\n",
    "                    new_file.write('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4d4b-29bd-40c4-bb87-ece21839d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\\\Users\\\\Leonardo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ded8d3",
   "metadata": {},
   "source": [
    "We then decided to build a .csv to collect all the data and to make them always available in a practical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r\"C:\\Users\\Leonardo\\ADM_HW3\\tsv\"\n",
    "final_dataset = []\n",
    "filenames = os.listdir(path)\n",
    "\n",
    "for file in filenames:\n",
    "    if file.endswith('tsv'):\n",
    "        file_path = os.path.join(path,file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep =\"\\t\", header=None, quoting=3)\n",
    "            final_dataset.append(df)\n",
    "        except:\n",
    "            print(file)\n",
    "            pass\n",
    "    \n",
    "final_dataset = pd.concat(final_dataset)\n",
    "final_dataset.to_csv('final_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdac034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"final_dataset.csv\"\n",
    "\n",
    "mostPopularPlaces = pd.read_csv(path)\n",
    "mostPopularPlaces = mostPopularPlaces.iloc[:, :-2]\n",
    "mostPopularPlaces.columns = ['placeName', 'placeTags', 'numPeopleVisited', 'numPeopleWant', 'placeDesc', 'placeShortDesc', 'placeNearby', \n",
    "        'placeAddress', 'placeAlt', 'placeLong', 'placeEditors', 'placePubDate', 'placeRelatedPlaces', 'placeRelatedLists', 'placeURL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50ebb1-6b01-4e0c-ac62-d6d364b9ba9c",
   "metadata": {},
   "source": [
    "We now have the whole dataset and we are ready to start building the search engines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1673fa-cf2d-494b-b215-e3f4468bf727",
   "metadata": {},
   "source": [
    "_________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1023031",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')                           #Download command on NLTK library to get specific \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb97ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntlk_analysis(info):\n",
    "    final_words = []\n",
    "    tokens = word_tokenize(info.lower())\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and token.encode().isalpha():\n",
    "            stemming_token = ps.stem(token)\n",
    "            final_words.append(stemming_token)\n",
    "            \n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87f2d1",
   "metadata": {},
   "source": [
    "## 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd48469",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfWords = []\n",
    "for index, row in mostPopularPlaces['placeDesc'].iteritems():\n",
    "    description = mostPopularPlaces['placeDesc'][index]\n",
    "    listOfWords.append(ntlk_analysis(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0027273",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopularPlaces['listOfWords'] = listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopularPlaces['listOfWords'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ce52b",
   "metadata": {},
   "source": [
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "term_id = 1\n",
    "for word in sorted(list(word_occ.keys())):\n",
    "    vocabulary[word] = term_id\n",
    "    term_id += 1\n",
    "\n",
    "with open('vocabulary.txt', 'w') as file:\n",
    "    for word, term_id in vocabulary.items():\n",
    "        file.write('%s:%s\\n' % (word, term_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c392da",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To open the vocabulary from vocabulary.text use this script\n",
    "'''\n",
    "vocabulary = {}\n",
    "with open('vocabulary.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        word = line.split(':')[0]\n",
    "        term_id = line.split(':')[1]\n",
    "        vocabulary[word] = int(term_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b65b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "for index, list_ in mostPopularPlaces['listOfWords'].iteritems():\n",
    "    for word in list_:\n",
    "        if word in inverted_index:\n",
    "            if index not in inverted_index[word]:\n",
    "                inverted_index[word].append(index)\n",
    "        else:\n",
    "            inverted_index[word] = [index]\n",
    "\n",
    "inverted_index = dict(sorted(inverted_index.items()))\n",
    "with open('inverted_index1.txt', 'w') as file:\n",
    "    for word, indexing in inverted_index.items():\n",
    "        texted_indexing = str(indexing[0]) + ', ' + ', '.join(list(map(str, indexing[1:])))\n",
    "        file.write('%s:%s\\n' % (word, texted_indexing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6975e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To open the vocabulary from vocabulary.text use this script\n",
    "'''\n",
    "\n",
    "inverted_index = {}\n",
    "with open('inverted_index1.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        word = line.split(':')[0]\n",
    "        indexing = line.split(':')[1].strip('\\n')\n",
    "        indexing = indexing.split(',')\n",
    "        if indexing[-1] == ' ':\n",
    "            indexing = indexing[:-1]\n",
    "        inverted_index[word] = list(map(int, [string.strip() for string in indexing]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ed274",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df9c2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_match(query,df):\n",
    "    result = []\n",
    "    query = ntlk_analysis(query)\n",
    "    match = {key: [] for key in query}\n",
    "\n",
    "    for key,list_of_values in inverted_index.items():\n",
    "        if key in match:\n",
    "            for value in list_of_values:\n",
    "                if value not in match[key]:\n",
    "                    match[key].append(value)\n",
    "                    \n",
    "    final_values = list(match.values())\n",
    "    intersection = set.intersection(*map(set,final_values))\n",
    "    \n",
    "    for index in intersection:\n",
    "        series = df[['placeName', 'placeDesc','placeURL']].loc[index]\n",
    "        result.append(series)\n",
    "    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2eccf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Catoctin Furnace</td>\n",
       "      <td>In the early 1770s, Thomas Johnson discovered ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/catoctin-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>U-505</td>\n",
       "      <td>One of only four remaining U-boats in the worl...</td>\n",
       "      <td>https://www.atlasobscura.com/places/u-505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Diego Rivera's Detroit Industry</td>\n",
       "      <td>In a city overflowing with street art, murals,...</td>\n",
       "      <td>https://www.atlasobscura.com/places/diego-rive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Cave Hill Cemetery</td>\n",
       "      <td>Holding the bodies of a number of influential ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/cave-hill-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>Mansfield Memorial Museum</td>\n",
       "      <td>Back at the 1939 World’s Fair in New York, Ele...</td>\n",
       "      <td>https://www.atlasobscura.com/places/mansfield-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Castle Post</td>\n",
       "      <td>Looking more like an abandoned Medieval Times ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/castle-post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Belgrade Tesla Museum</td>\n",
       "      <td>In the center of Belgrade, a villa holds the w...</td>\n",
       "      <td>https://www.atlasobscura.com/places/belgrade-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>Harvard Museum of Natural History</td>\n",
       "      <td>Collecting three different institutions into o...</td>\n",
       "      <td>https://www.atlasobscura.com/places/harvard-mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>KattenKabinet</td>\n",
       "      <td>The death of a pet can inspire a number of rea...</td>\n",
       "      <td>https://www.atlasobscura.com/places/kattenkabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>Mammoth Cave Wildlife Museum</td>\n",
       "      <td>Cave City is a wonderland of kitschy tourist t...</td>\n",
       "      <td>https://www.atlasobscura.com/places/mammoth-ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              placeName  \\\n",
       "1024                   Catoctin Furnace   \n",
       "6657                              U-505   \n",
       "1542    Diego Rivera's Detroit Industry   \n",
       "1031                 Cave Hill Cemetery   \n",
       "3593          Mansfield Memorial Museum   \n",
       "...                                 ...   \n",
       "1002                        Castle Post   \n",
       "495               Belgrade Tesla Museum   \n",
       "2548  Harvard Museum of Natural History   \n",
       "3060                      KattenKabinet   \n",
       "3574       Mammoth Cave Wildlife Museum   \n",
       "\n",
       "                                              placeDesc  \\\n",
       "1024  In the early 1770s, Thomas Johnson discovered ...   \n",
       "6657  One of only four remaining U-boats in the worl...   \n",
       "1542  In a city overflowing with street art, murals,...   \n",
       "1031  Holding the bodies of a number of influential ...   \n",
       "3593  Back at the 1939 World’s Fair in New York, Ele...   \n",
       "...                                                 ...   \n",
       "1002  Looking more like an abandoned Medieval Times ...   \n",
       "495   In the center of Belgrade, a villa holds the w...   \n",
       "2548  Collecting three different institutions into o...   \n",
       "3060  The death of a pet can inspire a number of rea...   \n",
       "3574  Cave City is a wonderland of kitschy tourist t...   \n",
       "\n",
       "                                               placeURL  \n",
       "1024  https://www.atlasobscura.com/places/catoctin-f...  \n",
       "6657          https://www.atlasobscura.com/places/u-505  \n",
       "1542  https://www.atlasobscura.com/places/diego-rive...  \n",
       "1031  https://www.atlasobscura.com/places/cave-hill-...  \n",
       "3593  https://www.atlasobscura.com/places/mansfield-...  \n",
       "...                                                 ...  \n",
       "1002    https://www.atlasobscura.com/places/castle-post  \n",
       "495   https://www.atlasobscura.com/places/belgrade-t...  \n",
       "2548  https://www.atlasobscura.com/places/harvard-mu...  \n",
       "3060  https://www.atlasobscura.com/places/kattenkabinet  \n",
       "3574  https://www.atlasobscura.com/places/mammoth-ca...  \n",
       "\n",
       "[239 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_search_engine = search_match('american museum', mostPopularPlaces)\n",
    "first_search_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8113784",
   "metadata": {},
   "source": [
    "# 2.2. Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbf2c3",
   "metadata": {},
   "source": [
    "We can leverage tfidf method from sklearn, or we can implement the tfidf from scratch. We will implement both solution as exercise, but we'll use *TfdifVectorizer* to focus on tuning the model on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20674b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### word_occ = Counter(reduce(lambda x,y:x+y, mostPopularPlaces.listOfWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4df43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a2c19a6",
   "metadata": {},
   "source": [
    "# 3. Define a new score!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae208a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = round(mostPopularPlaces['numPeopleVisited'].mean(),2)\n",
    "mean2 = round(mostPopularPlaces['numPeopleWant'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e0dd3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417.14 910.36\n"
     ]
    }
   ],
   "source": [
    "print(mean1, mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35f8e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_score_popularity(query, df, mean1, mean2, k):\n",
    "    result = []\n",
    "    query = ntlk_analysis(query)\n",
    "    match = {key: [] for key in query}\n",
    "\n",
    "    for key,list_of_values in inverted_index.items():\n",
    "        if key in match:\n",
    "            for value in list_of_values:\n",
    "                if value not in match[key]:\n",
    "                    match[key].append(value)\n",
    "\n",
    "\n",
    "    final_values = list(match.values())\n",
    "    intersection = set.intersection(*map(set,final_values))\n",
    "\n",
    "    rank = []\n",
    "    score = 0\n",
    "    for idx in intersection:\n",
    "        score = int(df.loc[idx]['numPeopleVisited'] > mean1) + int(df.loc[idx]['numPeopleWant'] > mean2)\n",
    "        rank.append((idx,score))\n",
    "        \n",
    "    heapq.heapify(rank) \n",
    "    rank = (heapq.nlargest(n = k, iterable = rank, key = lambda x:x[1])) \n",
    "\n",
    "    for idx,score in rank:\n",
    "        series = df[['placeName', 'placeDesc','placeURL']].loc[idx]\n",
    "        series['newScore'] = score\n",
    "        result.append(series)\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f968166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeURL</th>\n",
       "      <th>newScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A Christmas Story House and Museum</td>\n",
       "      <td>For many Americans, the 1983 film A Christmas ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/a-christma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Baldwin's Book Barn</td>\n",
       "      <td>There are places where history takes longer to...</td>\n",
       "      <td>https://www.atlasobscura.com/places/baldwins-b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>American Classic Arcade Museum</td>\n",
       "      <td>Housed inside New Hampshire’s Funspot, which h...</td>\n",
       "      <td>https://www.atlasobscura.com/places/american-c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Blue Mustang</td>\n",
       "      <td>The “Blue Mustang” sculpture was created by th...</td>\n",
       "      <td>https://www.atlasobscura.com/places/blue-mustang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>CDC Museum</td>\n",
       "      <td>In the 1995 hit film Outbreak, residents of th...</td>\n",
       "      <td>https://www.atlasobscura.com/places/cdc-museum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>Crazy Horse Memorial</td>\n",
       "      <td>When the carving of Mount Rushmore began in 19...</td>\n",
       "      <td>https://www.atlasobscura.com/places/crazy-hors...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Horniman Museum and Gardens</td>\n",
       "      <td>London’s Horniman Museum has been showing off ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/horniman-m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Canyons of the Ancients</td>\n",
       "      <td>Ripe for quiet reflection and simply awe-inspi...</td>\n",
       "      <td>https://www.atlasobscura.com/places/canyons-of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Flushing Meadows-Corona Park</td>\n",
       "      <td>After a long ride from Manhattan, most get off...</td>\n",
       "      <td>https://www.atlasobscura.com/places/flushing-m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Biosphere of Montreal</td>\n",
       "      <td>As their contribution to Montreal’s 1967 World...</td>\n",
       "      <td>https://www.atlasobscura.com/places/biosphere-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               placeName  \\\n",
       "33    A Christmas Story House and Museum   \n",
       "392                  Baldwin's Book Barn   \n",
       "193       American Classic Arcade Museum   \n",
       "634                         Blue Mustang   \n",
       "1051                          CDC Museum   \n",
       "1362                Crazy Horse Memorial   \n",
       "2723         Horniman Museum and Gardens   \n",
       "924              Canyons of the Ancients   \n",
       "1972        Flushing Meadows-Corona Park   \n",
       "586                Biosphere of Montreal   \n",
       "\n",
       "                                              placeDesc  \\\n",
       "33    For many Americans, the 1983 film A Christmas ...   \n",
       "392   There are places where history takes longer to...   \n",
       "193   Housed inside New Hampshire’s Funspot, which h...   \n",
       "634   The “Blue Mustang” sculpture was created by th...   \n",
       "1051  In the 1995 hit film Outbreak, residents of th...   \n",
       "1362  When the carving of Mount Rushmore began in 19...   \n",
       "2723  London’s Horniman Museum has been showing off ...   \n",
       "924   Ripe for quiet reflection and simply awe-inspi...   \n",
       "1972  After a long ride from Manhattan, most get off...   \n",
       "586   As their contribution to Montreal’s 1967 World...   \n",
       "\n",
       "                                               placeURL  newScore  \n",
       "33    https://www.atlasobscura.com/places/a-christma...         2  \n",
       "392   https://www.atlasobscura.com/places/baldwins-b...         2  \n",
       "193   https://www.atlasobscura.com/places/american-c...         2  \n",
       "634    https://www.atlasobscura.com/places/blue-mustang         2  \n",
       "1051     https://www.atlasobscura.com/places/cdc-museum         2  \n",
       "1362  https://www.atlasobscura.com/places/crazy-hors...         2  \n",
       "2723  https://www.atlasobscura.com/places/horniman-m...         2  \n",
       "924   https://www.atlasobscura.com/places/canyons-of...         2  \n",
       "1972  https://www.atlasobscura.com/places/flushing-m...         2  \n",
       "586   https://www.atlasobscura.com/places/biosphere-...         2  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_search_engine = new_score_popularity('american museum', mostPopularPlaces, mean1, mean2, 10)\n",
    "second_search_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bca79a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_score_jaccard(query, df, k):\n",
    "    result = []\n",
    "    query = ntlk_analysis(query)\n",
    "    match = {key: [] for key in query}\n",
    "\n",
    "    for key,list_of_values in inverted_index.items():\n",
    "        if key in match:\n",
    "            for value in list_of_values:\n",
    "                if value not in match[key]:\n",
    "                    match[key].append(value)\n",
    "\n",
    "\n",
    "    final_values = list(match.values())\n",
    "    intersection = set.intersection(*map(set,final_values))\n",
    "\n",
    "    rank = []\n",
    "    score = 0\n",
    "    for idx in intersection:\n",
    "        if type(df.loc[idx]['placeTags']) == str:\n",
    "            tags = ntlk_analysis(df.loc[idx]['placeTags'])\n",
    "            jaccard_idx = len(set(tags).intersection(query))/ len(set(tags).union(query))\n",
    "            rank.append((idx,jaccard_idx))\n",
    "        else:\n",
    "            rank.append((idx, -1))\n",
    "        \n",
    "    #rank.sort(key = lambda x:x[1], reverse = True)\n",
    "    heapq.heapify(rank) \n",
    "    rank = (heapq.nlargest(n = k, iterable = rank, key = lambda x:x[1])) \n",
    "\n",
    "    for idx,score in rank:\n",
    "        series = df[['placeName', 'placeDesc','placeURL']].loc[idx]\n",
    "        series['newScore'] = score\n",
    "        result.append(series)\n",
    "    \n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae19c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeURL</th>\n",
       "      <th>newScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>East Kong Yick Building at the Wing Luke Museum</td>\n",
       "      <td>In 1910, 170 early Chinese pioneers pooled the...</td>\n",
       "      <td>https://www.atlasobscura.com/places/east-kong-...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>National World War II Museum</td>\n",
       "      <td>Perhaps once thought too narrowly focused, th...</td>\n",
       "      <td>https://www.atlasobscura.com/places/national-w...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Rock Art Ranch</td>\n",
       "      <td>Rock Art Ranch, near Winslow, Arizona, is a pr...</td>\n",
       "      <td>https://www.atlasobscura.com/places/rock-art-r...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>Lunch Box Museum</td>\n",
       "      <td>Lunch boxes bring back a certain sense of nost...</td>\n",
       "      <td>https://www.atlasobscura.com/places/lunch-box-...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>Metropolitan Pit Stop</td>\n",
       "      <td>Metropolitan Pit Stop was founded by Jimmy Val...</td>\n",
       "      <td>https://www.atlasobscura.com/places/metropolit...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>Museum of the American Cocktail</td>\n",
       "      <td>They say that New Orleans is the home of the f...</td>\n",
       "      <td>https://www.atlasobscura.com/places/museum-ame...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>Mitsitam Native Foods Cafe</td>\n",
       "      <td>A visit to the National Mall in Washington, D....</td>\n",
       "      <td>https://www.atlasobscura.com/places/mitsitam-n...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>Harvard Museum of Natural History</td>\n",
       "      <td>Collecting three different institutions into o...</td>\n",
       "      <td>https://www.atlasobscura.com/places/harvard-mu...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>Drayton Hall</td>\n",
       "      <td>Considered one of the most beautiful examples ...</td>\n",
       "      <td>https://www.atlasobscura.com/places/drayton-hall</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>Hugh Mercer Apothecary Shop</td>\n",
       "      <td>Hugh Mercer was a Scot, a warrior, a friend of...</td>\n",
       "      <td>https://www.atlasobscura.com/places/hugh-merce...</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            placeName  \\\n",
       "1701  East Kong Yick Building at the Wing Luke Museum   \n",
       "4142                     National World War II Museum   \n",
       "4979                                   Rock Art Ranch   \n",
       "3528                                 Lunch Box Museum   \n",
       "3734                            Metropolitan Pit Stop   \n",
       "3990                  Museum of the American Cocktail   \n",
       "3807                       Mitsitam Native Foods Cafe   \n",
       "2548                Harvard Museum of Natural History   \n",
       "1636                                     Drayton Hall   \n",
       "2791                      Hugh Mercer Apothecary Shop   \n",
       "\n",
       "                                              placeDesc  \\\n",
       "1701  In 1910, 170 early Chinese pioneers pooled the...   \n",
       "4142   Perhaps once thought too narrowly focused, th...   \n",
       "4979  Rock Art Ranch, near Winslow, Arizona, is a pr...   \n",
       "3528  Lunch boxes bring back a certain sense of nost...   \n",
       "3734  Metropolitan Pit Stop was founded by Jimmy Val...   \n",
       "3990  They say that New Orleans is the home of the f...   \n",
       "3807  A visit to the National Mall in Washington, D....   \n",
       "2548  Collecting three different institutions into o...   \n",
       "1636  Considered one of the most beautiful examples ...   \n",
       "2791  Hugh Mercer was a Scot, a warrior, a friend of...   \n",
       "\n",
       "                                               placeURL  newScore  \n",
       "1701  https://www.atlasobscura.com/places/east-kong-...  0.500000  \n",
       "4142  https://www.atlasobscura.com/places/national-w...  0.333333  \n",
       "4979  https://www.atlasobscura.com/places/rock-art-r...  0.333333  \n",
       "3528  https://www.atlasobscura.com/places/lunch-box-...  0.333333  \n",
       "3734  https://www.atlasobscura.com/places/metropolit...  0.333333  \n",
       "3990  https://www.atlasobscura.com/places/museum-ame...  0.333333  \n",
       "3807  https://www.atlasobscura.com/places/mitsitam-n...  0.333333  \n",
       "2548  https://www.atlasobscura.com/places/harvard-mu...  0.333333  \n",
       "1636   https://www.atlasobscura.com/places/drayton-hall  0.285714  \n",
       "2791  https://www.atlasobscura.com/places/hugh-merce...  0.285714  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_search_engine = new_score_jaccard('american museum', mostPopularPlaces,10)\n",
    "third_search_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4a0a7142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'museums'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularPlaces.loc[1701]['placeTags']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "979bf14ea64443ff3ffb738d52926696eb30c1bf62b3b549289c26deae58448a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
